{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d08c90e-61f3-4031-bb27-0767af3efdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c72e21-5963-4244-b353-7bf1e5b4c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, split, trial):\n",
    "    return train_test_split(X, y, test_size=1 - split, random_state=trial, stratify=y)\n",
    "\n",
    "def balance_training_data(X_train, y_train, trial):\n",
    "    train_data = pd.concat([X_train, y_train], axis=1)\n",
    "    openai_data = train_data[train_data['y'] == 'OpenAI']\n",
    "    antrophic_data = train_data[train_data['y'] == 'Antrophic']\n",
    "    mistral_data = train_data[train_data['y'] == 'Mistral']\n",
    "\n",
    "    antrophic_oversampled = resample(antrophic_data, \n",
    "                                     replace=True,\n",
    "                                     n_samples=len(openai_data),\n",
    "                                     random_state=trial)\n",
    "    mistral_oversampled = resample(mistral_data, \n",
    "                                   replace=True,\n",
    "                                   n_samples=len(openai_data),\n",
    "                                   random_state=trial)\n",
    "\n",
    "    balanced_train_data = pd.concat([openai_data, antrophic_oversampled, mistral_oversampled])\n",
    "    balanced_train_data = balanced_train_data.sample(frac=1, random_state=trial).reset_index(drop=True)\n",
    "\n",
    "    X_train_balanced = balanced_train_data.drop(columns=['y', 'Unnamed: 0'])\n",
    "    \n",
    "    y_train_balanced = balanced_train_data['y']\n",
    "\n",
    "    return X_train_balanced, y_train_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b153ef3-5963-45a0-8074-8167a4deea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test):\n",
    "    # Keep only float64 columns\n",
    "    X_train = X_train.select_dtypes(include=['float64'])\n",
    "    X_test = X_test.select_dtypes(include=['float64'])\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Save scaler\n",
    "    joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "    return X_train, X_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8cad599-da68-4414-a4f6-ee5f0d6825f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(X_train, X_test, dim):\n",
    "    if dim > 0:\n",
    "        pca = PCA(n_components=dim)\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        return X_train, X_test, pca\n",
    "    return X_train, X_test, None\n",
    "\n",
    "def train_and_evaluate(classifier, X_train, y_train, X_test, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccad9ca-b6b6-484b-895d-618c7fd4c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testClassifier(classifier, X, y, dim=0, split=0.7, ntrials=100, save_best_model=True, model_filename=\"Best_Model.pkl\"):\n",
    "    means = np.zeros(ntrials)\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    best_label_encoders = None\n",
    "    best_pca = None  # Initialize as None\n",
    "\n",
    "    for trial in range(ntrials):\n",
    "        # Split \n",
    "        X_train, X_test, y_train, y_test = split_data(X, y, split, trial)\n",
    "\n",
    "        # Balance \n",
    "        X_train_balanced, y_train_balanced = balance_training_data(X_train, y_train, trial)\n",
    "\n",
    "        X_test = X_test.drop(columns=['Unnamed: 0'])\n",
    "        y_test = y_test.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "        # Preprocess \n",
    "        X_train_balanced, X_test, scaler = preprocess_data(X_train_balanced, X_test)\n",
    "\n",
    "        # PCA \n",
    "        X_train_balanced, X_test, pca = apply_pca(X_train_balanced, X_test, dim)\n",
    "\n",
    "        # Classifier\n",
    "        accuracy = train_and_evaluate(classifier, X_train_balanced, y_train_balanced, X_test, y_test)\n",
    "        means[trial] = accuracy * 100  # Convert to percentage\n",
    "\n",
    "        # Save the best model and PCA\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = classifier\n",
    "            best_pca = pca  # Save the best PCA object\n",
    "\n",
    "        # Print \n",
    "        if trial % 10 == 0:\n",
    "            print(f\"Trial {trial}: Accuracy = {accuracy * 100:.3f}%\")\n",
    "\n",
    "    mean_accuracy = np.mean(means)\n",
    "    std_accuracy = np.std(means)\n",
    "\n",
    "    print(f\"Overall mean: {mean_accuracy:.3f}%, sd: {std_accuracy:.3f}%\")\n",
    "\n",
    "    # Save the best model and preprocessing objects\n",
    "    if save_best_model and best_model is not None:\n",
    "        joblib.dump(best_model, model_filename)\n",
    "        joblib.dump(scaler, \"scaler.pkl\")\n",
    "        if best_pca is not None:\n",
    "            joblib.dump(best_pca, \"pca.pkl\")  # Save the best PCA object\n",
    "        print(f\"Best model: {best_accuracy * 100:.3f}%\")\n",
    "\n",
    "    return mean_accuracy, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc2945e-d535-4111-bd37-1b3e4e95cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "file_path = \"TrainOnMe.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Split into train and test before preprocessing\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ccbda54-4c5d-45d2-a40f-7c5034d5b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Accuracy = 79.280%\n",
      "Trial 10: Accuracy = 79.614%\n",
      "Trial 20: Accuracy = 79.813%\n",
      "Trial 30: Accuracy = 78.947%\n",
      "Trial 40: Accuracy = 80.546%\n",
      "Trial 50: Accuracy = 79.813%\n",
      "Trial 60: Accuracy = 78.148%\n",
      "Trial 70: Accuracy = 79.014%\n",
      "Trial 80: Accuracy = 80.546%\n",
      "Trial 90: Accuracy = 78.947%\n",
      "Overall mean: 79.843%, sd: 1.112%\n",
      "Best model: 83.411%\n",
      "Mean: 79.843%\n",
      "sd: 1.112%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Test the classifier and save the best model\n",
    "mean_acc, std_acc = testClassifier(\n",
    "    rf_classifier, \n",
    "    X, \n",
    "    y, \n",
    "    dim=11,  \n",
    "    split=0.7, \n",
    "    ntrials=100, \n",
    "    save_best_model=True, \n",
    "    model_filename=\"RandomForest_BestModel.pkl\"\n",
    ")\n",
    "\n",
    "print(f\"Mean: {mean_acc:.3f}%\")\n",
    "print(f\"sd: {std_acc:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfbb5dff-3e82-41e8-a73e-b73adf63fc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions successfully saved to prediction.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "eval_data = pd.read_csv(\"EvaluateOnMe.csv\")\n",
    "eval_data_processed = eval_data.drop(eval_data.columns[0], axis=1)\n",
    "\n",
    "model = joblib.load(\"RandomForest_BestModel.pkl\")\n",
    "\n",
    "# preprocessing objects\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "pca = joblib.load(\"pca.pkl\")\n",
    "\n",
    "def preprocess_eval_data(eval_data, scaler):\n",
    "    # Keep only float64 columns\n",
    "    eval_data = eval_data.select_dtypes(include=['float64'])\n",
    "\n",
    "    # Scale numerical features\n",
    "    eval_data = scaler.transform(eval_data)\n",
    "\n",
    "    return eval_data\n",
    "\n",
    "# preprocessing\n",
    "eval_data_processed = preprocess_eval_data(eval_data_processed, scaler)\n",
    "eval_data_processed = pca.transform(eval_data_processed)\n",
    "\n",
    "predictions = model.predict(eval_data_processed)\n",
    "\n",
    "with open(\"prediction.txt\", \"w\") as file:\n",
    "    for pred in predictions:\n",
    "        file.write(f\"{pred}\\n\")\n",
    "\n",
    "print(\"Predictions successfully saved to prediction.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbbbe0e-0600-4076-b26c-0b6d4abfb49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
